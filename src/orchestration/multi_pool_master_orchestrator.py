#!/usr/bin/env python3
"""
ZION Multi-Pool Orchestration Master Controller
Complete Multi-Pool Mining Ecosystem Coordinator

This module implements the master controller for:
- Multi-pool orchestration coordination
- Intelligent pool switching integration
- Geographic load balancing integration
- Distributed mining coordination
- Performance optimization across all pools
- Real-time adaptation and learning
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import redis
import json
import statistics
import numpy as np
from dataclasses import dataclass
from enum import Enum

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OrchestrationMode(Enum):
    """Enumeration of orchestration modes"""
    OPTIMIZE_PROFIT = "optimize_profit"
    BALANCE_LOAD = "balance_load"
    MAXIMIZE_STABILITY = "maximize_stability"
    GEOGRAPHIC_DISTRIBUTION = "geographic_distribution"
    ADAPTIVE_LEARNING = "adaptive_learning"

@dataclass
class OrchestrationState:
    """Data class for orchestration state"""
    mode: OrchestrationMode
    active_pools: List[str]
    total_hashrate: float
    efficiency_score: float
    profit_rate: float
    geographic_balance: float
    last_adaptation: datetime

@dataclass
class SystemMetrics:
    """Data class for system-wide metrics"""
    total_hashrate: float
    active_miners: int
    pool_count: int
    geographic_regions: int
    average_profitability: float
    system_efficiency: float
    network_latency: float

class MultiPoolOrchestrationMaster:
    """Master controller for complete multi-pool orchestration ecosystem"""

    def __init__(self, redis_host: str = 'localhost', redis_port: int = 6379):
        self.redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)

        # Orchestration state
        self.orchestration_state = OrchestrationState(
            mode=OrchestrationMode.OPTIMIZE_PROFIT,
            active_pools=[],
            total_hashrate=0.0,
            efficiency_score=0.0,
            profit_rate=0.0,
            geographic_balance=0.0,
            last_adaptation=datetime.now()
        )

        # Component coordinators
        self.pool_switcher_active = False
        self.geographic_balancer_active = False
        self.distributed_orchestrator_active = False

        # Performance tracking
        self.system_metrics_history = []
        self.orchestration_decisions = []
        self.performance_trends = {}

        # Adaptation parameters
        self.adaptation_interval = 1800  # 30 minutes
        self.performance_window = 3600  # 1 hour analysis window
        self.confidence_threshold = 0.75

        # Component PIDs for monitoring
        self.component_pids = {}

        logger.info("Multi-Pool Orchestration Master initialized")

    async def start_master_orchestration(self):
        """Start the master orchestration system"""
        logger.info("Starting ZION Multi-Pool Orchestration Master...")

        # Start component monitoring
        asyncio.create_task(self.component_health_monitor())

        # Start system monitoring
        asyncio.create_task(self.system_metrics_collector())

        # Start orchestration decision engine
        asyncio.create_task(self.orchestration_decision_engine())

        # Start adaptation engine
        asyncio.create_task(self.adaptive_learning_engine())

        # Start emergency response system
        asyncio.create_task(self.emergency_response_system())

        logger.info("Multi-Pool Orchestration Master started")

    async def component_health_monitor(self):
        """Monitor health of all orchestration components"""
        while True:
            try:
                # Check pool switcher health
                await self._check_pool_switcher_health()

                # Check geographic balancer health
                await self._check_geographic_balancer_health()

                # Check distributed orchestrator health
                await self._check_distributed_orchestrator_health()

                # Update component status
                await self._update_component_status()

                await asyncio.sleep(60)  # Check every minute

            except Exception as e:
                logger.error(f"Error in component health monitor: {e}")
                await asyncio.sleep(30)

    async def _check_pool_switcher_health(self):
        """Check health of intelligent pool switcher"""
        try:
            # Check if switcher is responding
            switcher_status = self.redis_client.get('switcher:statistics')

            if switcher_status:
                status_data = json.loads(switcher_status)
                self.pool_switcher_active = True

                # Check if status is recent (within 5 minutes)
                last_update = datetime.fromisoformat(status_data.get('updated_at', '2000-01-01T00:00:00'))
                if (datetime.now() - last_update).total_seconds() > 300:
                    logger.warning("Pool switcher status is stale")
                    self.pool_switcher_active = False
            else:
                self.pool_switcher_active = False

        except Exception as e:
            logger.error(f"Error checking pool switcher health: {e}")
            self.pool_switcher_active = False

    async def _check_geographic_balancer_health(self):
        """Check health of geographic load balancer"""
        try:
            balancer_status = self.redis_client.get('balancer:efficiency')

            if balancer_status:
                self.geographic_balancer_active = True
            else:
                self.geographic_balancer_active = False

        except Exception as e:
            logger.error(f"Error checking geographic balancer health: {e}")
            self.geographic_balancer_active = False

    async def _check_distributed_orchestrator_health(self):
        """Check health of distributed mining orchestrator"""
        try:
            orchestrator_status = self.redis_client.get('orchestrator:status')

            if orchestrator_status:
                status_data = json.loads(orchestrator_status)
                last_update = datetime.fromisoformat(status_data.get('last_update', '2000-01-01T00:00:00'))

                if (datetime.now() - last_update).total_seconds() < 300:
                    self.distributed_orchestrator_active = True
                else:
                    self.distributed_orchestrator_active = False
            else:
                self.distributed_orchestrator_active = False

        except Exception as e:
            logger.error(f"Error checking distributed orchestrator health: {e}")
            self.distributed_orchestrator_active = False

    async def _update_component_status(self):
        """Update overall component status"""
        try:
            component_status = {
                'pool_switcher': {
                    'active': self.pool_switcher_active,
                    'last_checked': datetime.now().isoformat()
                },
                'geographic_balancer': {
                    'active': self.geographic_balancer_active,
                    'last_checked': datetime.now().isoformat()
                },
                'distributed_orchestrator': {
                    'active': self.distributed_orchestrator_active,
                    'last_checked': datetime.now().isoformat()
                },
                'overall_health': self._calculate_overall_health()
            }

            self.redis_client.setex(
                'master:component_status',
                120,  # 2 minutes
                json.dumps(component_status)
            )

        except Exception as e:
            logger.error(f"Error updating component status: {e}")

    def _calculate_overall_health(self) -> str:
        """Calculate overall system health"""
        active_components = sum([
            self.pool_switcher_active,
            self.geographic_balancer_active,
            self.distributed_orchestrator_active
        ])

        if active_components == 3:
            return 'excellent'
        elif active_components == 2:
            return 'good'
        elif active_components == 1:
            return 'degraded'
        else:
            return 'critical'

    async def system_metrics_collector(self):
        """Collect comprehensive system metrics"""
        while True:
            try:
                # Collect metrics from all components
                metrics = await self._collect_system_metrics()

                # Store metrics history
                self.system_metrics_history.append(metrics)

                # Keep only recent history
                cutoff_time = datetime.now() - timedelta(hours=24)
                self.system_metrics_history = [
                    m for m in self.system_metrics_history
                    if datetime.fromisoformat(m['timestamp']) > cutoff_time
                ]

                # Update trends
                await self._update_performance_trends()

                # Publish system status
                await self._publish_system_status(metrics)

                await asyncio.sleep(300)  # Collect every 5 minutes

            except Exception as e:
                logger.error(f"Error collecting system metrics: {e}")
                await asyncio.sleep(60)

    async def _collect_system_metrics(self) -> Dict[str, Any]:
        """Collect comprehensive system metrics"""
        try:
            metrics = SystemMetrics(
                total_hashrate=0.0,
                active_miners=0,
                pool_count=0,
                geographic_regions=0,
                average_profitability=0.0,
                system_efficiency=0.0,
                network_latency=0.0
            )

            # Collect from pool switcher
            if self.pool_switcher_active:
                switcher_data = self.redis_client.get('switcher:statistics')
                if switcher_data:
                    data = json.loads(switcher_data)
                    metrics.pool_count = len(data.get('available_pools', []))
                    metrics.average_profitability = data.get('average_profit_increase', 0)

            # Collect from geographic balancer
            if self.geographic_balancer_active:
                balancer_data = self.redis_client.get('balancer:efficiency')
                if balancer_data:
                    data = json.loads(balancer_data)
                    metrics.geographic_regions = len(data)
                    # Calculate average efficiency
                    efficiencies = [region_data['efficiency'] for region_data in data.values()]
                    metrics.system_efficiency = statistics.mean(efficiencies) if efficiencies else 0

            # Collect from distributed orchestrator
            if self.distributed_orchestrator_active:
                orchestrator_data = self.redis_client.get('orchestrator:metrics')
                if orchestrator_data:
                    data = json.loads(orchestrator_data)
                    metrics.total_hashrate = data.get('total_hashrate', 0)
                    metrics.active_miners = data.get('active_miners', 0)
                    metrics.network_latency = data.get('avg_latency', 0)

            return {
                'timestamp': datetime.now().isoformat(),
                'total_hashrate': metrics.total_hashrate,
                'active_miners': metrics.active_miners,
                'pool_count': metrics.pool_count,
                'geographic_regions': metrics.geographic_regions,
                'average_profitability': metrics.average_profitability,
                'system_efficiency': metrics.system_efficiency,
                'network_latency': metrics.network_latency,
                'orchestration_mode': self.orchestration_state.mode.value
            }

        except Exception as e:
            logger.error(f"Error collecting system metrics: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'error': str(e)
            }

    async def _update_performance_trends(self):
        """Update performance trends analysis"""
        try:
            if len(self.system_metrics_history) < 5:
                return

            recent_metrics = self.system_metrics_history[-20:]  # Last 20 entries

            # Calculate trends for key metrics
            hashrate_values = [m['total_hashrate'] for m in recent_metrics if 'total_hashrate' in m]
            if hashrate_values:
                self.performance_trends['hashrate_trend'] = self._calculate_trend(hashrate_values)

            profitability_values = [m['average_profitability'] for m in recent_metrics if 'average_profitability' in m]
            if profitability_values:
                self.performance_trends['profitability_trend'] = self._calculate_trend(profitability_values)

            efficiency_values = [m['system_efficiency'] for m in recent_metrics if 'system_efficiency' in m]
            if efficiency_values:
                self.performance_trends['efficiency_trend'] = self._calculate_trend(efficiency_values)

        except Exception as e:
            logger.error(f"Error updating performance trends: {e}")

    def _calculate_trend(self, values: List[float]) -> float:
        """Calculate trend for a series of values"""
        try:
            if len(values) < 2:
                return 0.0

            x = np.arange(len(values))
            slope, _ = np.polyfit(x, values, 1)
            return slope / max(abs(statistics.mean(values)), 0.0001)

        except Exception:
            return 0.0

    async def _publish_system_status(self, metrics: Dict[str, Any]):
        """Publish comprehensive system status"""
        try:
            system_status = {
                'metrics': metrics,
                'orchestration_state': {
                    'mode': self.orchestration_state.mode.value,
                    'active_pools': self.orchestration_state.active_pools,
                    'total_hashrate': self.orchestration_state.total_hashrate,
                    'efficiency_score': self.orchestration_state.efficiency_score,
                    'profit_rate': self.orchestration_state.profit_rate,
                    'geographic_balance': self.orchestration_state.geographic_balance,
                    'last_adaptation': self.orchestration_state.last_adaptation.isoformat()
                },
                'component_health': json.loads(self.redis_client.get('master:component_status') or '{}'),
                'performance_trends': self.performance_trends,
                'last_updated': datetime.now().isoformat()
            }

            self.redis_client.setex(
                'master:system_status',
                60,  # 1 minute
                json.dumps(system_status)
            )

        except Exception as e:
            logger.error(f"Error publishing system status: {e}")

    async def orchestration_decision_engine(self):
        """Main orchestration decision engine"""
        while True:
            try:
                # Analyze current system state
                system_analysis = await self._analyze_system_state()

                # Make orchestration decisions
                decisions = await self._make_orchestration_decisions(system_analysis)

                # Execute decisions
                if decisions:
                    await self._execute_orchestration_decisions(decisions)

                await asyncio.sleep(600)  # Make decisions every 10 minutes

            except Exception as e:
                logger.error(f"Error in orchestration decision engine: {e}")
                await asyncio.sleep(120)

    async def _analyze_system_state(self) -> Dict[str, Any]:
        """Analyze current system state for decision making"""
        try:
            analysis = {
                'component_health': self._calculate_overall_health(),
                'performance_trends': self.performance_trends.copy(),
                'system_metrics': self.system_metrics_history[-1] if self.system_metrics_history else {},
                'imbalances': {},
                'opportunities': {},
                'risks': {}
            }

            # Analyze imbalances
            if self.pool_switcher_active:
                imbalances = self.redis_client.get('switcher:imbalances')
                if imbalances:
                    analysis['imbalances']['pool_distribution'] = json.loads(imbalances)

            if self.geographic_balancer_active:
                geo_imbalances = self.redis_client.get('balancer:imbalances')
                if geo_imbalances:
                    analysis['imbalances']['geographic'] = json.loads(geo_imbalances)

            # Identify opportunities
            analysis['opportunities'] = await self._identify_opportunities()

            # Assess risks
            analysis['risks'] = await self._assess_system_risks()

            return analysis

        except Exception as e:
            logger.error(f"Error analyzing system state: {e}")
            return {'error': str(e)}

    async def _identify_opportunities(self) -> Dict[str, Any]:
        """Identify optimization opportunities"""
        try:
            opportunities = {}

            # Pool switching opportunities
            if self.pool_switcher_active:
                prediction = await self._get_pool_switcher_prediction()
                if prediction and prediction.get('confidence', 0) > self.confidence_threshold:
                    opportunities['pool_switching'] = prediction

            # Geographic balancing opportunities
            if self.geographic_balancer_active:
                geo_prediction = await self._get_geographic_prediction()
                if geo_prediction:
                    opportunities['geographic_rebalancing'] = geo_prediction

            # Performance optimization opportunities
            if self.performance_trends.get('profitability_trend', 0) < -0.1:
                opportunities['performance_optimization'] = {
                    'issue': 'Declining profitability',
                    'trend': self.performance_trends['profitability_trend'],
                    'recommendation': 'Consider pool switching or parameter optimization'
                }

            return opportunities

        except Exception as e:
            logger.error(f"Error identifying opportunities: {e}")
            return {}

    async def _get_pool_switcher_prediction(self) -> Optional[Dict[str, Any]]:
        """Get prediction from pool switcher"""
        try:
            # This would call the pool switcher's prediction method
            # For now, return mock data
            return {
                'recommended_pool': 'zion-optimized',
                'expected_improvement': 0.08,
                'confidence': 0.85,
                'time_horizon': 1
            }
        except Exception:
            return None

    async def _get_geographic_prediction(self) -> Optional[Dict[str, Any]]:
        """Get prediction from geographic balancer"""
        try:
            # This would call the geographic balancer's prediction method
            return {
                'regions_needing_adjustment': ['asia', 'europe'],
                'expected_balance_improvement': 0.15
            }
        except Exception:
            return None

    async def _assess_system_risks(self) -> Dict[str, Any]:
        """Assess system-wide risks"""
        try:
            risks = {}

            # Component health risks
            if not self.pool_switcher_active:
                risks['pool_switcher_down'] = {'severity': 'high', 'impact': 'No intelligent pool switching'}

            if not self.geographic_balancer_active:
                risks['geographic_balancer_down'] = {'severity': 'medium', 'impact': 'No geographic optimization'}

            if not self.distributed_orchestrator_active:
                risks['distributed_orchestrator_down'] = {'severity': 'high', 'impact': 'No distributed coordination'}

            # Performance risks
            if self.performance_trends.get('efficiency_trend', 0) < -0.2:
                risks['efficiency_decline'] = {
                    'severity': 'high',
                    'trend': self.performance_trends['efficiency_trend']
                }

            return risks

        except Exception as e:
            logger.error(f"Error assessing system risks: {e}")
            return {}

    async def _make_orchestration_decisions(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Make orchestration decisions based on analysis"""
        try:
            decisions = []

            # Decision making based on orchestration mode
            if self.orchestration_state.mode == OrchestrationMode.OPTIMIZE_PROFIT:
                decisions.extend(await self._optimize_profit_decisions(analysis))

            elif self.orchestration_state.mode == OrchestrationMode.BALANCE_LOAD:
                decisions.extend(await self._balance_load_decisions(analysis))

            elif self.orchestration_state.mode == OrchestrationMode.MAXIMIZE_STABILITY:
                decisions.extend(await self._maximize_stability_decisions(analysis))

            elif self.orchestration_state.mode == OrchestrationMode.GEOGRAPHIC_DISTRIBUTION:
                decisions.extend(await self._geographic_distribution_decisions(analysis))

            # Add emergency decisions if needed
            emergency_decisions = await self._emergency_decisions(analysis)
            decisions.extend(emergency_decisions)

            return decisions

        except Exception as e:
            logger.error(f"Error making orchestration decisions: {e}")
            return []

    async def _optimize_profit_decisions(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Make decisions optimized for profit"""
        decisions = []

        # Check for pool switching opportunities
        opportunities = analysis.get('opportunities', {})
        if 'pool_switching' in opportunities:
            pool_opportunity = opportunities['pool_switching']
            if pool_opportunity['expected_improvement'] > 0.05:  # 5% improvement threshold
                decisions.append({
                    'type': 'pool_switch',
                    'target_pool': pool_opportunity['recommended_pool'],
                    'expected_profit_increase': pool_opportunity['expected_improvement'],
                    'reason': 'Profit optimization'
                })

        return decisions

    async def _balance_load_decisions(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Make decisions for load balancing"""
        decisions = []

        # Check geographic imbalances
        imbalances = analysis.get('imbalances', {})
        if 'geographic' in imbalances:
            geo_imbalances = imbalances['geographic']
            for imbalance in geo_imbalances:
                if imbalance['severity'] == 'high':
                    decisions.append({
                        'type': 'geographic_rebalance',
                        'region': imbalance['region'],
                        'action': 'reduce' if imbalance['current'] > imbalance['target'] else 'increase',
                        'reason': 'Load balancing'
                    })

        return decisions

    async def _maximize_stability_decisions(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Make decisions for stability maximization"""
        decisions = []

        # Focus on reducing volatility
        trends = analysis.get('performance_trends', {})
        if trends.get('profitability_trend', 0) < -0.1:
            decisions.append({
                'type': 'stability_mode',
                'action': 'enable_conservative_switching',
                'reason': 'Stability maximization'
            })

        return decisions

    async def _geographic_distribution_decisions(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Make decisions for geographic distribution"""
        decisions = []

        # Optimize geographic distribution
        opportunities = analysis.get('opportunities', {})
        if 'geographic_rebalancing' in opportunities:
            geo_opportunity = opportunities['geographic_rebalancing']
            decisions.append({
                'type': 'geographic_optimization',
                'regions': geo_opportunity['regions_needing_adjustment'],
                'expected_improvement': geo_opportunity['expected_balance_improvement'],
                'reason': 'Geographic distribution optimization'
            })

        return decisions

    async def _emergency_decisions(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Make emergency decisions when needed"""
        decisions = []

        risks = analysis.get('risks', {})

        # Critical component failures
        if 'pool_switcher_down' in risks or 'distributed_orchestrator_down' in risks:
            decisions.append({
                'type': 'emergency_fallback',
                'action': 'switch_to_manual_mode',
                'reason': 'Critical component failure'
            })

        # Severe performance decline
        if 'efficiency_decline' in risks:
            risk_data = risks['efficiency_decline']
            if risk_data['severity'] == 'high':
                decisions.append({
                    'type': 'emergency_optimization',
                    'action': 'immediate_rebalancing',
                    'reason': 'Severe efficiency decline'
                })

        return decisions

    async def _execute_orchestration_decisions(self, decisions: List[Dict[str, Any]]):
        """Execute orchestration decisions"""
        try:
            logger.info(f"Executing {len(decisions)} orchestration decisions")

            for decision in decisions:
                # Send decision to appropriate component
                decision_command = {
                    'type': 'orchestration_decision',
                    'decision': decision,
                    'timestamp': datetime.now().isoformat(),
                    'master_id': 'zion-master-orchestrator'
                }

                # Route to appropriate channel
                if decision['type'] == 'pool_switch':
                    self.redis_client.publish('mining:pool_switches', json.dumps(decision_command))
                elif decision['type'] in ['geographic_rebalance', 'geographic_optimization']:
                    self.redis_client.publish('mining:rebalance', json.dumps(decision_command))
                else:
                    self.redis_client.publish('orchestrator:decisions', json.dumps(decision_command))

                logger.info(f"Executed decision: {decision['type']} - {decision.get('reason', 'No reason')}")

                # Store decision history
                self.orchestration_decisions.append({
                    'decision': decision,
                    'timestamp': datetime.now().isoformat(),
                    'executed': True
                })

            # Keep decision history limited
            if len(self.orchestration_decisions) > 100:
                self.orchestration_decisions = self.orchestration_decisions[-100:]

        except Exception as e:
            logger.error(f"Error executing orchestration decisions: {e}")

    async def adaptive_learning_engine(self):
        """Adaptive learning engine for continuous optimization"""
        while True:
            try:
                # Analyze performance patterns
                patterns = await self._analyze_performance_patterns()

                # Learn from successful decisions
                await self._learn_from_decisions()

                # Adapt orchestration parameters
                await self._adapt_orchestration_parameters(patterns)

                # Update orchestration mode if needed
                await self._update_orchestration_mode()

                await asyncio.sleep(self.adaptation_interval)

            except Exception as e:
                logger.error(f"Error in adaptive learning engine: {e}")
                await asyncio.sleep(300)

    async def _analyze_performance_patterns(self) -> Dict[str, Any]:
        """Analyze performance patterns for learning"""
        try:
            if len(self.system_metrics_history) < 10:
                return {}

            # Analyze patterns in metrics
            patterns = {
                'peak_performance_times': [],
                'low_performance_periods': [],
                'successful_decisions': [],
                'failed_decisions': []
            }

            # Analyze decision success rates
            recent_decisions = self.orchestration_decisions[-20:]
            successful_decisions = [d for d in recent_decisions if d.get('success', False)]
            patterns['decision_success_rate'] = len(successful_decisions) / len(recent_decisions) if recent_decisions else 0

            return patterns

        except Exception as e:
            logger.error(f"Error analyzing performance patterns: {e}")
            return {}

    async def _learn_from_decisions(self):
        """Learn from past orchestration decisions"""
        try:
            # Analyze successful vs failed decisions
            successful = [d for d in self.orchestration_decisions if d.get('success', False)]
            failed = [d for d in self.orchestration_decisions if not d.get('success', False)]

            if successful and failed:
                # Learn patterns for success
                success_types = [d['decision']['type'] for d in successful]
                most_successful_type = max(set(success_types), key=success_types.count)

                logger.info(f"Most successful decision type: {most_successful_type}")

                # Adjust confidence thresholds based on success rates
                success_rate = len(successful) / len(self.orchestration_decisions)
                if success_rate > 0.8:
                    self.confidence_threshold = min(0.9, self.confidence_threshold + 0.05)
                elif success_rate < 0.6:
                    self.confidence_threshold = max(0.6, self.confidence_threshold - 0.05)

        except Exception as e:
            logger.error(f"Error learning from decisions: {e}")

    async def _adapt_orchestration_parameters(self, patterns: Dict[str, Any]):
        """Adapt orchestration parameters based on learning"""
        try:
            # Adapt decision intervals based on system volatility
            if self.performance_trends.get('profitability_trend', 0) > 0.1:
                # High positive trend - be more aggressive
                self.adaptation_interval = max(900, self.adaptation_interval - 300)
            elif self.performance_trends.get('profitability_trend', 0) < -0.1:
                # Negative trend - be more conservative
                self.adaptation_interval = min(3600, self.adaptation_interval + 300)

            # Update last adaptation time
            self.orchestration_state.last_adaptation = datetime.now()

        except Exception as e:
            logger.error(f"Error adapting orchestration parameters: {e}")

    async def _update_orchestration_mode(self):
        """Update orchestration mode based on conditions"""
        try:
            # Switch modes based on system conditions
            current_mode = self.orchestration_state.mode

            # If system is unstable, switch to stability mode
            if self._calculate_overall_health() == 'critical':
                new_mode = OrchestrationMode.MAXIMIZE_STABILITY
            elif self.performance_trends.get('profitability_trend', 0) < -0.2:
                new_mode = OrchestrationMode.OPTIMIZE_PROFIT
            elif len(self.system_metrics_history) > 0:
                latest_metrics = self.system_metrics_history[-1]
                geographic_regions = latest_metrics.get('geographic_regions', 0)
                if geographic_regions > 5:  # Many regions, focus on geographic distribution
                    new_mode = OrchestrationMode.GEOGRAPHIC_DISTRIBUTION
                else:
                    new_mode = OrchestrationMode.BALANCE_LOAD
            else:
                new_mode = OrchestrationMode.OPTIMIZE_PROFIT

            if new_mode != current_mode:
                logger.info(f"Switching orchestration mode: {current_mode.value} -> {new_mode.value}")
                self.orchestration_state.mode = new_mode

        except Exception as e:
            logger.error(f"Error updating orchestration mode: {e}")

    async def emergency_response_system(self):
        """Emergency response system for critical situations"""
        while True:
            try:
                # Monitor for emergency conditions
                emergency = await self._detect_emergency_conditions()

                if emergency:
                    await self._execute_emergency_response(emergency)

                await asyncio.sleep(30)  # Check every 30 seconds

            except Exception as e:
                logger.error(f"Error in emergency response system: {e}")
                await asyncio.sleep(60)

    async def _detect_emergency_conditions(self) -> Optional[Dict[str, Any]]:
        """Detect emergency conditions requiring immediate response"""
        try:
            # Check component failures
            if not any([self.pool_switcher_active, self.geographic_balancer_active, self.distributed_orchestrator_active]):
                return {
                    'type': 'total_system_failure',
                    'severity': 'critical',
                    'description': 'All orchestration components failed'
                }

            # Check performance collapse
            if self.system_metrics_history:
                latest = self.system_metrics_history[-1]
                if latest.get('system_efficiency', 1.0) < 0.1:  # Less than 10% efficiency
                    return {
                        'type': 'performance_collapse',
                        'severity': 'critical',
                        'description': 'System efficiency critically low'
                    }

            # Check rapid decline
            if len(self.system_metrics_history) > 5:
                recent_efficiency = [m.get('system_efficiency', 0) for m in self.system_metrics_history[-5:]]
                if recent_efficiency and self._calculate_trend(recent_efficiency) < -0.5:
                    return {
                        'type': 'rapid_decline',
                        'severity': 'high',
                        'description': 'Rapid performance decline detected'
                    }

            return None

        except Exception as e:
            logger.error(f"Error detecting emergency conditions: {e}")
            return None

    async def _execute_emergency_response(self, emergency: Dict[str, Any]):
        """Execute emergency response actions"""
        try:
            logger.critical(f"EMERGENCY RESPONSE: {emergency['description']}")

            # Emergency actions based on type
            if emergency['type'] == 'total_system_failure':
                # Switch to manual/fallback mode
                await self._activate_emergency_mode()

            elif emergency['type'] == 'performance_collapse':
                # Immediate rebalancing and optimization
                await self._emergency_rebalancing()

            elif emergency['type'] == 'rapid_decline':
                # Conservative stabilization
                await self._emergency_stabilization()

            # Log emergency response
            emergency_log = {
                'emergency': emergency,
                'response_timestamp': datetime.now().isoformat(),
                'system_state': await self._get_emergency_system_state()
            }

            self.redis_client.lpush('master:emergency_log', json.dumps(emergency_log))

        except Exception as e:
            logger.error(f"Error executing emergency response: {e}")

    async def _activate_emergency_mode(self):
        """Activate emergency fallback mode"""
        try:
            # Switch to most basic orchestration mode
            self.orchestration_state.mode = OrchestrationMode.MAXIMIZE_STABILITY

            # Send emergency commands to surviving components
            emergency_command = {
                'type': 'emergency_mode',
                'action': 'activate_fallback',
                'timestamp': datetime.now().isoformat()
            }

            self.redis_client.publish('orchestrator:emergency', json.dumps(emergency_command))

            logger.critical("Emergency mode activated - system operating in fallback mode")

        except Exception as e:
            logger.error(f"Error activating emergency mode: {e}")

    async def _emergency_rebalancing(self):
        """Execute emergency rebalancing"""
        try:
            # Force immediate rebalancing across all components
            rebalance_command = {
                'type': 'emergency_rebalance',
                'action': 'immediate_full_rebalance',
                'timestamp': datetime.now().isoformat()
            }

            self.redis_client.publish('mining:emergency', json.dumps(rebalance_command))

            logger.critical("Emergency rebalancing initiated")

        except Exception as e:
            logger.error(f"Error executing emergency rebalancing: {e}")

    async def _emergency_stabilization(self):
        """Execute emergency stabilization"""
        try:
            # Conservative parameter adjustments
            stabilization_command = {
                'type': 'emergency_stabilization',
                'action': 'conservative_parameters',
                'timestamp': datetime.now().isoformat()
            }

            self.redis_client.publish('orchestrator:stabilization', json.dumps(stabilization_command))

            logger.critical("Emergency stabilization initiated")

        except Exception as e:
            logger.error(f"Error executing emergency stabilization: {e}")

    async def _get_emergency_system_state(self) -> Dict[str, Any]:
        """Get system state during emergency"""
        try:
            return {
                'component_status': {
                    'pool_switcher': self.pool_switcher_active,
                    'geographic_balancer': self.geographic_balancer_active,
                    'distributed_orchestrator': self.distributed_orchestrator_active
                },
                'orchestration_mode': self.orchestration_state.mode.value,
                'system_metrics': self.system_metrics_history[-1] if self.system_metrics_history else {},
                'performance_trends': self.performance_trends
            }

        except Exception as e:
            return {'error': str(e)}

    async def get_master_status(self) -> Dict[str, Any]:
        """Get comprehensive master orchestrator status"""
        try:
            return {
                'orchestration_state': {
                    'mode': self.orchestration_state.mode.value,
                    'active_pools': self.orchestration_state.active_pools,
                    'total_hashrate': self.orchestration_state.total_hashrate,
                    'efficiency_score': self.orchestration_state.efficiency_score,
                    'profit_rate': self.orchestration_state.profit_rate,
                    'geographic_balance': self.orchestration_state.geographic_balance,
                    'last_adaptation': self.orchestration_state.last_adaptation.isoformat()
                },
                'component_health': {
                    'pool_switcher': self.pool_switcher_active,
                    'geographic_balancer': self.geographic_balancer_active,
                    'distributed_orchestrator': self.distributed_orchestrator_active,
                    'overall_health': self._calculate_overall_health()
                },
                'system_metrics': self.system_metrics_history[-1] if self.system_metrics_history else {},
                'performance_trends': self.performance_trends,
                'recent_decisions': self.orchestration_decisions[-5:] if self.orchestration_decisions else [],
                'last_updated': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"Error getting master status: {e}")
            return {'error': str(e)}

    def set_orchestration_mode(self, mode: OrchestrationMode):
        """Set the orchestration mode"""
        try:
            logger.info(f"Setting orchestration mode to: {mode.value}")
            self.orchestration_state.mode = mode

        except Exception as e:
            logger.error(f"Error setting orchestration mode: {e}")

async def main():
    """Main function for multi-pool orchestration master"""
    master = MultiPoolOrchestrationMaster()

    # Start master orchestration
    await master.start_master_orchestration()

    # Keep running
    while True:
        await asyncio.sleep(60)

        # Log status periodically
        status = await master.get_master_status()
        logger.info(f"Master Orchestrator Status: Mode={status['orchestration_state']['mode']}, "
                   f"Health={status['component_health']['overall_health']}")

if __name__ == "__main__":
    asyncio.run(main())